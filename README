*** Sujet ***

 Le but du sujet est de construire un outil en ligne de commande de correction
 orthographique rapide et stable en utilisant une distance de Damerau-Levenshtein.
 Lorsqu'on compile le projet, on obtient deux éxécutables :

  - TextMiningCompiler : sert à dumper un dictionnaire à partir d'un
    fichier rempli de lignes contenant chacune un mot ainsi que sa fréquence.
  - TextMiningApp : charge un dictionnaire et fait des recherches dessus en
    prenant en compte une distance maximale d'erreur définie dans l'input. La
    sortie est en format JSON.

Ce projet permet de réfléchir à des problématiques de la vrai vie, notamment
comment gérer énormément de données et pouvoir faire des recherches dessus,
tout en étant efficace, quelles optimisations peut-on faire pour aller plus
vite, prendre moins d'espace, etc.

*** Compilation ***

Pour compiler ce projet, il suffit de faire ./configue && make

*** Questions ***

  1. Decrivez les choix de design de votre programme.

    Notre programme se décompose en plusieurs parties.

    Premièrement, il lit le le fichier contenant l'ensemble des mots et des
    fréquences pour construire un Dict, qui est un vecteur d'Entry, chaque Entry
    possédent un champ pour le mot, et un champ pour la fréquence.

    Ensuite, un TrieBuilder est crée, c'est la première représentation de notre
    structure de données. Cette implémentation est totalement naïve, c'est un
    arbre de map. Le principe est de mettre chaque lettre sur une arrête.
    Au début le TrieBuilder est un simple Trie, puis on le compact pour le
    transformer en Patricia Trie.

    La prochaine étape, est la sérialisation:
    Pour cela on a commence par penser a la deserialization.
    Il nous fallait un structure rapide a deserializser, qui support des acces rapides, et de preference le random access
    On a donc desider de transforme la representation intermediaire, en un memory block contant:
    Des Trie:
        - Le nombre de TrieElemnt 
        - Un array de TrieElement
    Les TrieElement vont servir pour faire la transition entre les differents Trie.
    TrieElement:
        - Offset vers un aute Trie en partant de l'adresse du TrieElement
        - Information concernant l'arc: label, s'il est terminal, la frequance du mot cumuler

                                  __________________
                                 /                  V
   ---------------------------------------------------------------------------
   | TrieElement Count | TrieElement|TrieElement|...| TrieElement Count|....
   ---------------------------------------------------------------------------
                                             \_________________________......

    Avec une tel structure on peut se servir de mmap pour mapper le datablock directement en memoire, sans avec a se
    preocuper de la copie. Dans l'idee, on a choisi de faviser les pagefault et eviter de copier tout le fichier en
    memoire.

    Enfin, pour la recherche, on n'utilise pas de calcul de distance de
    Damerau-Levenshtei directement, nous avons choisi de propager la recherche
    avec plusieurs types de recherche :
    - une pour tester si les deux caractères sont identiques,
    - une pour tester si il y a une lettre en plus dans le mot cherché,
    - une pour tester si il y a une lettre en moins,
    - une pour tester si il y a une substitution,
    - une pour tester si il y a un swap de lettre

    Chaque résultat est stockée dans une structure de données, puis une fois la
    recherche terminée, on affiche tout les résultats en format JSON.

  2. Listez l’ensemble des tests effectués sur votre programme (en plus des
     units tests)

     $ make test
     on test la construction
     le resultat de la serialisation
     et les differentes etape de la recheche sous forme de test unitaire, ou la majeure partie des tests decoulent des
     problemes rencontre

     $ ./configure && make bench
     On test aussi directement contre la ref, histoire de s'assurer du bon fonctionnement de notre programme comparer a la ref

  3. Avez-vous détecté des cas où la correction par distance ne fonctionnait
     pas (même avec une distance  élevée) ?

     La correction par distance omet de considerer le contexte et est limite a un dictionnaire pre-existant.
     Et ne fait pas la difference entre les differents type de mots (ex: .net)

  4. Quelle est la structure de données que vous avez implémentée dans votre
     projet, pourquoi ?

    Dans notre projet, nous avons décidé d'implémenter un Patricia Trie.
    Un Patricia Trie est un trie optimisé pour prendre moins d'espace. Le
    but est de compacter les préfixes d'un trie, pour avoir moins de noeuds
    représentés. Ceci peut être efficace si par exemple on travaille avec des
    urls : au lieu d'avoir plein d'arrêtes pour h, t, t, p, :, /, /, on se
    retrouve avec une seule arrête contenant http://. Le gain en espace est
    très satisfaisant. Il possède aussi les avantages du Trie, qui tire son
    nom de "retrieval", qui signifie que la structure de donnée a été pensée
    pour être optimal pour la recherche d'information sur une base de données
    tirées d'une multitudes de sources différentes.

  5. Proposez un réglage automatique de la distance pour un programme qui prend
     juste une chaîne de caractères en entrée, donner le processus d’évaluation
     ainsi que les résultats.

    // FIXME comprend pas la question

  6. Comment comptez vous améliorer les performances de votre programme

    Il est possible d'améliorer les performances de notre programme en travaillant
    plus en amont, lors de la sérialisation de notre Patricia Trie. En effet, il
    serait efficace de pouvoir merger des branches qui se termineraient de la
    même façon, et ainsi prendre moins d'espace en mémoire.
    // FIXME t'as des idées ?
